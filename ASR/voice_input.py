import sounddevice as sd
import numpy as np
import threading
import queue
import librosa
import webrtcvad
import logging
import sys
from sense_voice_service import SenseVoiceService

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler(sys.stdout)]
)
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

class VoiceInput:
    """
    è¯­éŸ³è¾“å…¥ç±»ï¼Œæ”¯æŒè‡ªåŠ¨é‡é‡‡æ ·ã€å¤šé€šé“æ··åˆæˆ–é€‰æ‹©ã€å¯é…ç½®ç¼“å†²é•¿åº¦ï¼Œå¹¶æ·»åŠ VADæ£€æµ‹ã€‚
    """
    def __init__(self):
        """
        åˆå§‹åŒ–è¯­éŸ³è¾“å…¥ç±»ï¼Œæ‰€æœ‰å‚æ•°éƒ½åœ¨å†…éƒ¨è®¾ç½®
        """
        logger.info("åˆå§‹åŒ– VoiceInput...")
        
        # è‡ªåŠ¨æ£€æµ‹é»˜è®¤è®¾å¤‡ä¿¡æ¯
        dev_info = sd.query_devices(kind='input')
        self.input_rate = int(dev_info['default_samplerate'])
        self.channels = dev_info['max_input_channels']

        # ç›®æ ‡æ ¼å¼è®¾ç½®
        self.target_rate = 16000  # æ¨¡å‹æœŸæœ›çš„é‡‡æ ·ç‡
        self.mix_channels = True  # æ˜¯å¦å°†å¤šå£°é“éŸ³é¢‘å–å‡å€¼æ··åˆä¸ºå•å£°é“
        self.lib_resample = True  # æ˜¯å¦ä½¿ç”¨ librosa é‡é‡‡æ ·
        self.chunk_duration = 0.1  # å¤„ç†æ—¶é•¿0.1ç§’
        self.chunk_frames = int(self.chunk_duration * self.target_rate)

        # VADé…ç½®
        self.vad_aggressiveness = 0  # é™ä½VADæ•æ„Ÿåº¦ï¼ŒèŒƒå›´0-3ï¼Œ0æœ€ä¸æ•æ„Ÿ
        self.vad_frame_duration = 30  # VADæ£€æµ‹çš„å¸§é•¿åº¦ï¼Œå•ä½æ¯«ç§’
        self.vad = webrtcvad.Vad(self.vad_aggressiveness)
        self.vad_frame_size = int(self.target_rate * self.vad_frame_duration / 1000)
        self.vad_buffer = np.zeros((0,), dtype=np.float32)  # ç”¨äºVADæ£€æµ‹çš„ç¼“å†²åŒº
        self.vad_buffer_duration = 0.5  # å¢åŠ VADæ£€æµ‹çš„ç¼“å†²åŒºæ—¶é•¿åˆ°0.5ç§’
        self.vad_buffer_size = int(self.vad_buffer_duration * self.target_rate)
        
        # ä¸­æ–‡è¯­éŸ³ç‰¹å¾æ£€æµ‹é…ç½®
        self.min_volume = 0.02  # æœ€å°éŸ³é‡é˜ˆå€¼
        self.max_volume = 0.5   # æœ€å¤§éŸ³é‡é˜ˆå€¼
        self.min_freq = 100     # æœ€å°é¢‘ç‡é˜ˆå€¼ï¼ˆHzï¼‰
        self.max_freq = 1000    # æœ€å¤§é¢‘ç‡é˜ˆå€¼ï¼ˆHzï¼‰
        
        # è¯­éŸ³ç¼“å­˜é…ç½®
        self.speech_buffer = np.zeros((0,), dtype=np.float32)  # ç”¨äºç´¯ç§¯è¯­éŸ³ç‰‡æ®µ
        self.is_speaking = False  # æ˜¯å¦æ­£åœ¨è¯´è¯
        self.silence_frames = 0  # è¿ç»­é™éŸ³å¸§è®¡æ•°
        self.max_silence_frames = 10  # å¢åŠ æœ€å¤§å…è®¸çš„è¿ç»­é™éŸ³å¸§æ•°
        self.min_speech_frames = 3  # æœ€å°éœ€è¦è¿ç»­æ£€æµ‹åˆ°è¯­éŸ³çš„å¸§æ•°
        
        logger.debug(f"VADé…ç½® - æ•æ„Ÿåº¦: {self.vad_aggressiveness}, å¸§å¤§å°: {self.vad_frame_size}, ç¼“å†²åŒºå¤§å°: {self.vad_buffer_size}")

        # ç¼“å†²ä¸é˜Ÿåˆ—
        self.audio_queue = queue.Queue()  # ç”¨äºå­˜å‚¨å¾…å¤„ç†çš„éŸ³é¢‘æ•°æ®
        self.transcribe_queue = queue.Queue()  # ç”¨äºå­˜å‚¨å¾…è½¬å†™çš„éŸ³é¢‘æ•°æ®

        # å½•éŸ³çŠ¶æ€
        self.recording = False

        # åˆå§‹åŒ–æœåŠ¡
        try:
            self.svc = SenseVoiceService()
            logger.info("SenseVoice æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"SenseVoice æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
            self.svc = None
            
        # æ–‡æœ¬å›è°ƒå‡½æ•°
        self.on_text_received = None

    def _audio_callback(self, indata, frames, time, status):
        """éŸ³é¢‘å›è°ƒå‡½æ•°"""
        if status:
            logger.warning(f"å½•éŸ³çŠ¶æ€: {status}")
        # æ”¾å…¥çº¿ç¨‹å®‰å…¨é˜Ÿåˆ—
        self.audio_queue.put(indata.copy())

    def start(self):
        """å¼€å§‹å½•éŸ³å¹¶å¯åŠ¨å¤„ç†çº¿ç¨‹"""
        if self.recording:
            logger.warning("å½•éŸ³å·²ç»åœ¨è¿›è¡Œä¸­")
            return
            
        logger.info("å¼€å§‹å½•éŸ³...")
        self.recording = True

        # å¯åŠ¨å½•éŸ³çº¿ç¨‹
        self.record_thread = threading.Thread(target=self._record_loop, daemon=True)
        self.record_thread.start()
        
        # å¯åŠ¨è½¬å†™çº¿ç¨‹
        self.transcribe_thread = threading.Thread(target=self._transcribe_loop, daemon=True)
        self.transcribe_thread.start()
        
        logger.info("å½•éŸ³å’Œè½¬å†™çº¿ç¨‹å·²å¯åŠ¨")

    def _record_loop(self):
        """å½•éŸ³çº¿ç¨‹ä¸»å¾ªç¯"""
        logger.info("å¯åŠ¨å½•éŸ³çº¿ç¨‹")
        try:
            # è®¡ç®—å—å¤§å°ï¼Œç¡®ä¿è‡³å°‘åŒ…å«ä¸€ä¸ªVADå¸§
            blocksize = int(self.target_rate * self.vad_frame_duration / 1000)  # 30msçš„é‡‡æ ·ç‚¹æ•°
            logger.info(f"è®¾ç½®éŸ³é¢‘å—å¤§å°: {blocksize} é‡‡æ ·ç‚¹")
            
            with sd.InputStream(
                samplerate=self.input_rate,
                channels=self.channels,
                dtype='float32',
                blocksize=blocksize,  # è®¾ç½®å—å¤§å°
                callback=self._audio_callback,
            ):
                logger.info("éŸ³é¢‘è¾“å…¥æµå·²æ‰“å¼€")
                while self.recording:
                    try:
                        chunk = self.audio_queue.get(timeout=1)
                        self._process_chunk(chunk)
                    except queue.Empty:
                        continue
        except Exception as e:
            logger.error(f"å½•éŸ³é”™è¯¯: {e}")
            self.recording = False

    def _transcribe_loop(self):
        """è½¬å†™çº¿ç¨‹ä¸»å¾ªç¯"""
        logger.info("å¯åŠ¨è½¬å†™çº¿ç¨‹")
        while self.recording:
            try:
                # ä»è½¬å†™é˜Ÿåˆ—è·å–éŸ³é¢‘æ•°æ®
                audio_data = self.transcribe_queue.get(timeout=0.5)
                if audio_data is None:
                    logger.info("è½¬å†™é˜Ÿåˆ—ä¸­æ²¡æœ‰æ•°æ®")
                    continue

                logger.info("å¼€å§‹è½¬å†™")   
                # å¤„ç†éŸ³é¢‘æ•°æ®
                result = self.svc.transcribe(audio_data, language="auto")
                if result.get("error"):
                    logger.error(f"è½¬å†™é”™è¯¯: {result['error']}")
                elif result.get("text"):
                    logger.info(f"è¯†åˆ«ç»“æœ: {result['text']}")
                    # è°ƒç”¨æ–‡æœ¬å›è°ƒå‡½æ•°
                    if self.on_text_received is not None:
                        self.on_text_received(result["text"])
                    
            except queue.Empty:
                continue
            except Exception as e:
                logger.error(f"è½¬å†™é”™è¯¯: {e}")
                continue
                
        logger.info("è½¬å†™çº¿ç¨‹å·²åœæ­¢")

    def _check_chinese_speech(self, audio_data):
        """æ£€æŸ¥æ˜¯å¦ç¬¦åˆä¸­æ–‡è¯­éŸ³ç‰¹å¾"""
        # è®¡ç®—éŸ³é‡
        volume = np.max(np.abs(audio_data))
        if volume < self.min_volume or volume > self.max_volume:
            logger.debug(f"éŸ³é‡ {volume:.4f} è¶…å‡ºèŒƒå›´ [{self.min_volume}, {self.max_volume}]")
            return False
            
        # è®¡ç®—é¢‘è°±
        n_fft = 2048
        hop_length = 512
        D = np.abs(librosa.stft(audio_data, n_fft=n_fft, hop_length=hop_length))
        freqs = librosa.fft_frequencies(sr=self.target_rate, n_fft=n_fft)
        
        # è®¡ç®—ä¸»è¦é¢‘ç‡æˆåˆ†
        power = np.sum(D, axis=1)
        main_freq = freqs[np.argmax(power)]
        
        if main_freq < self.min_freq or main_freq > self.max_freq:
            logger.debug(f"ä¸»è¦é¢‘ç‡ {main_freq:.1f}Hz è¶…å‡ºèŒƒå›´ [{self.min_freq}, {self.max_freq}]Hz")
            return False
            
        return True

    def _process_chunk(self, raw_chunk):
        """å¤„ç†éŸ³é¢‘å—"""        
        # åŸå§‹æµ®ç‚¹ PCM [-1, 1]
        data = raw_chunk.astype(np.float32)

        # å¤„ç†å¤šé€šé“ -> å•é€šé“
        if data.ndim == 2:
            if self.mix_channels:
                mono = data.mean(axis=1)
            else:
                mono = data[:, 0]
        else:
            mono = data.flatten()

        # é‡é‡‡æ ·åˆ°ç›®æ ‡é‡‡æ ·ç‡
        if self.input_rate != self.target_rate:
            resampled = librosa.resample(
                mono, orig_sr=self.input_rate, target_sr=self.target_rate
            )
        else:
            resampled = mono

        # ç´¯ç§¯éŸ³é¢‘æ•°æ®åˆ°VADç¼“å†²åŒº
        self.vad_buffer = np.concatenate([self.vad_buffer, resampled])
        if len(self.vad_buffer) > self.vad_buffer_size:
            self.vad_buffer = self.vad_buffer[-self.vad_buffer_size:]
            
            # è¿›è¡Œ VAD æ£€æµ‹
            is_speech = self._vad_detect(self.vad_buffer)
            logger.debug(f"VADæ£€æµ‹ç»“æœ: {is_speech}")
            
            if is_speech:
                # æ£€æŸ¥æ˜¯å¦ç¬¦åˆä¸­æ–‡è¯­éŸ³ç‰¹å¾
                if not self._check_chinese_speech(self.vad_buffer):
                    is_speech = False
                    logger.debug("ä¸ç¬¦åˆä¸­æ–‡è¯­éŸ³ç‰¹å¾")
            
            if is_speech:
                # æ£€æµ‹åˆ°è¯­éŸ³
                self.silence_frames = 0  # é‡ç½®é™éŸ³è®¡æ•°
                if not self.is_speaking:
                    # ä»é™éŸ³å˜ä¸ºè¯­éŸ³ï¼Œå¼€å§‹æ–°çš„è¯­éŸ³ç‰‡æ®µ
                    self.is_speaking = True
                    self.speech_buffer = np.zeros((0,), dtype=np.float32)  # æ¸…ç©ºä¹‹å‰çš„ç¼“å­˜
                    logger.info("ğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹")
                
                # ç´¯ç§¯éŸ³é¢‘æ•°æ®åˆ°è¯­éŸ³ç¼“å†²åŒº
                self.speech_buffer = np.concatenate([self.speech_buffer, resampled])
            else:
                # æ£€æµ‹åˆ°é™éŸ³
                if self.is_speaking:
                    self.silence_frames += 1
                    if self.silence_frames >= self.max_silence_frames:
                        # è¿ç»­é™éŸ³å¸§æ•°è¾¾åˆ°é˜ˆå€¼ï¼Œè®¤ä¸ºè¯­éŸ³ç»“æŸ
                        self.is_speaking = False
                        logger.info("ğŸ”• æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ")
                        
                        # å°†ç´¯ç§¯çš„è¯­éŸ³æ•°æ®æ”¾å…¥è½¬å†™é˜Ÿåˆ—
                        if len(self.speech_buffer) > 0:
                            logger.info("ğŸ“¤ å‘é€è¯­éŸ³ç‰‡æ®µåˆ°è½¬å†™æœåŠ¡")
                            self.transcribe_queue.put(self.speech_buffer)
                            self.speech_buffer = np.zeros((0,), dtype=np.float32)
                    else:
                        # ä»åœ¨è¯­éŸ³ç‰‡æ®µä¸­ï¼Œç»§ç»­ç´¯ç§¯éŸ³é¢‘æ•°æ®
                        self.speech_buffer = np.concatenate([self.speech_buffer, resampled])

    def _vad_detect(self, audio_data):
        """ä½¿ç”¨ WebRTC VAD æ£€æµ‹è¯­éŸ³æ´»åŠ¨"""
        # å°†æµ®ç‚¹éŸ³é¢‘æ•°æ®è½¬æ¢ä¸º 16 ä½æ•´æ•°
        audio_int16 = (audio_data * 32767).astype(np.int16)
        
        # å°†éŸ³é¢‘æ•°æ®åˆ†å‰²æˆ VAD å¸§
        frames = []
        for i in range(0, len(audio_int16), self.vad_frame_size):
            frame = audio_int16[i:i + self.vad_frame_size]
            if len(frame) == self.vad_frame_size:
                frames.append(frame)
        
        # æ£€æµ‹æ¯ä¸ªå¸§
        speech_frames = 0
        for frame in frames:
            if self.vad.is_speech(frame.tobytes(), self.target_rate):
                speech_frames += 1
        
        # å¦‚æœè¶…è¿‡ä¸€åŠçš„å¸§è¢«æ£€æµ‹ä¸ºè¯­éŸ³ï¼Œåˆ™è®¤ä¸ºæœ‰è¯­éŸ³æ´»åŠ¨
        return speech_frames > len(frames) / 2

    def stop(self):
        """åœæ­¢å½•éŸ³"""
        if not self.recording:
            logger.warning("å½•éŸ³å·²ç»åœæ­¢")
            return
            
        logger.info("æ­£åœ¨åœæ­¢å½•éŸ³...")
        self.recording = False
        
        # ç­‰å¾…çº¿ç¨‹ç»“æŸ
        if hasattr(self, 'record_thread'):
            self.record_thread.join(timeout=1)
        if hasattr(self, 'transcribe_thread'):
            self.transcribe_thread.join(timeout=1)
            
        logger.info("å½•éŸ³å·²åœæ­¢")
